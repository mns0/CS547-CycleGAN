{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cyclegan.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M6JSLcTkNb2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "# CS 547 Deep learning Final Report: CycleGAN Code Notebook Version\n",
        "### Group Member: Chuqiao Shi, JOsh Vita, Manish Shanka, Tim Murry\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBX2L3XflEdS",
        "colab_type": "text"
      },
      "source": [
        "This is the CycleGAN code in a Jupyter Notebook. This can be easily \n",
        "run on the Google Colab Free GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnB53bptTHci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check the GPU type in the colab, noramlly the Tesla P100 is the best one\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WISgs1ZtoNRv",
        "colab_type": "text"
      },
      "source": [
        "## Import packages and global variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_1z1jkOl9Jf",
        "colab_type": "text"
      },
      "source": [
        "Connect the files in the Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_fiOU3lTWV-",
        "colab_type": "code",
        "outputId": "90d4da59-2fd6-46e3-892a-f42304b80f4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUWdkF7PmDmE",
        "colab_type": "text"
      },
      "source": [
        "Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIaKTUkHTWyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.autograd import Variable, grad\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w88qxGBpiBDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 150\n",
        "batch_size = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4BOug3KmI8o",
        "colab_type": "text"
      },
      "source": [
        "## Preparing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioyhGV-zmRo_",
        "colab_type": "text"
      },
      "source": [
        "Define the dataloader to input training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nLMLQ-d6Ncd_",
        "colab": {}
      },
      "source": [
        "class cycle_data(Dataset):\n",
        "\n",
        "    def __init__(self, path, train):\n",
        "\n",
        "        self.paintings = []\n",
        "        self.photos = []\n",
        "\n",
        "        if train:\n",
        "            train_str = 'train'\n",
        "        else:\n",
        "            train_str = 'test'\n",
        "\n",
        "        # Training the cycleGAN for painting<->photo transformation, \n",
        "        # A is for paintings and B is for photos\n",
        "\n",
        "        painting_path = path + train_str + 'A/'\n",
        "        photo_path = path + train_str + 'B/'\n",
        "\n",
        "        print(painting_path, len(os.listdir(painting_path)))\n",
        "        print(photo_path, len(os.listdir(photo_path)))\n",
        "\n",
        "        for painting_name in os.listdir(painting_path):\n",
        "            self.paintings.append(painting_path + painting_name)\n",
        "\n",
        "        for photo_name in os.listdir(photo_path):\n",
        "            self.photos.append(photo_path + photo_name)\n",
        "\n",
        "        self.paintings_size = len(self.paintings)\n",
        "        self.photos_size = len(self.photos)\n",
        "\n",
        "        self.size = max(self.paintings_size, self.photos_size)\n",
        "        # self.size = min(self.paintings_size, self.photos_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        # TODO: handle the fact that paintings and photos aren't same length\n",
        "        # Random pick up the photo & image pairs\n",
        "        x_idx = idx % self.paintings_size\n",
        "        y_idx = np.random.randint(0, self.photos_size - 1)\n",
        "\n",
        "        x ,y = plt.imread(self.paintings[x_idx]), plt.imread(self.photos[y_idx])\n",
        "        x = (x-np.min(x))/np.ptp(x)\n",
        "        y = (y-np.min(y))/np.ptp(y)\n",
        "\n",
        "        x = np.moveaxis(x,(0,1,2),(1,2,0))\n",
        "        y = np.moveaxis(y,(0,1,2),(1,2,0))\n",
        "        return x,y\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U0Xx-qqnPzv",
        "colab_type": "text"
      },
      "source": [
        "Sample fake images from the image pool, this class can save the memory during training the discriminator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzYKXt61GXQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sample_from_Pool(object):\n",
        "    def __init__(self, max_elements=50):\n",
        "        self.max_elements = max_elements\n",
        "        self.cur_elements = 0\n",
        "        self.items = []\n",
        "\n",
        "    def __call__(self, in_items):\n",
        "        \n",
        "        return_items = []\n",
        "        for in_item in in_items:\n",
        "            # If there are under 50 images in the image pool, add new images in the pool\n",
        "            if self.cur_elements < self.max_elements:\n",
        "                self.items.append(in_item)\n",
        "                self.cur_elements = self.cur_elements + 1\n",
        "                return_items.append(in_item)\n",
        "            # If there are moe than 50 images, randomly sample images to replce the fake images\n",
        "            # from the generator\n",
        "            else:\n",
        "                if np.random.ranf() > 0.5:\n",
        "                    idx = np.random.randint(0, self.max_elements)\n",
        "                    tmp = copy.copy(self.items[idx])\n",
        "                    self.items[idx] = in_item\n",
        "                    return_items.append(tmp)\n",
        "                else:\n",
        "                    return_items.append(in_item)\n",
        "        return return_items"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4bovPuqoupE",
        "colab_type": "text"
      },
      "source": [
        "Data Transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "652IKG_QgIwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "transform_train = transforms.Compose([\n",
        "    \n",
        "    \n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0, 0, 0), (1, 1, 1))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0, 0, 0), (1, 1, 1)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg2vX3JDozCl",
        "colab_type": "text"
      },
      "source": [
        "Define the data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76sKwZFshZSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = cycle_data('/content/drive/My Drive/ukiyoe2photo/ukiyoe2photo/', train=True)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
        "\n",
        "testset = cycle_data('/content/drive/My Drive/ukiyoe2photo/ukiyoe2photo/', train=False)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJg-NiyGo1yp",
        "colab_type": "text"
      },
      "source": [
        "## Define the CycleGAN Structures\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXkkBZp7p0dr",
        "colab_type": "text"
      },
      "source": [
        "CycleGAN includes a generator and a discriminator. The generator is an auto-encoder convolutional network with Res blocks in the middle to generate fake images. The discriminator includes the convolution layers and fully connective layers to indentify fake and real images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YplVgmMxqL4D",
        "colab_type": "text"
      },
      "source": [
        "### Define the generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x6q_N0scRgjX",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,32,3,padding=1)\n",
        "        self.norm1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32,64,3,padding=1)\n",
        "        self.norm2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64,128,3,padding=1)\n",
        "        self.norm3 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        self.lru = nn.LeakyReLU()\n",
        "        self.maxpool = nn.MaxPool2d(2,2)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        x = self.lru(self.norm1(self.conv1(x)))\n",
        "        x = self.maxpool(x)\n",
        "        x = self.lru(self.norm2(self.conv2(x)))\n",
        "        x = self.maxpool(x)\n",
        "        x = self.lru(self.norm3(self.conv3(x)))\n",
        "        x = self.maxpool(x)\n",
        "        \n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvqwDP0jqn-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv4 = nn.Conv2d(128,128,3,padding=1)\n",
        "        self.lru = nn.LeakyReLU()\n",
        "        self.norm3 = nn.BatchNorm2d(128)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        temp_in = x\n",
        "        x = self.lru(self.norm3(self.conv4(x)))\n",
        "        x = self.norm3(self.conv4(x))\n",
        "\n",
        "        return x + temp_in\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dklm0iY1rHHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        \n",
        "        self.conv6 = nn.Sequential(\n",
        "            nn.Upsample(scale_factor = 2, mode='bilinear'),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=0)\n",
        "        )\n",
        "        self.conv7 = nn.Sequential(\n",
        "            nn.Upsample(scale_factor = 2, mode='bilinear'),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=0)\n",
        "        )\n",
        "        self.conv8 = nn.Sequential(\n",
        "            nn.Upsample(scale_factor = 2, mode='bilinear'),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(32, 3, kernel_size=3, stride=1, padding=0)\n",
        "        )\n",
        "       \n",
        "        self.norm1 = nn.BatchNorm2d(64)\n",
        "        self.norm0 = nn.BatchNorm2d(32)\n",
        "        self.lru = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        x = self.lru(self.norm1(self.conv6(x)))\n",
        "        x = self.lru(self.norm0(self.conv7(x)))\n",
        "        x = self.conv8(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P57GNtuViB_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class generator(nn.Module):\n",
        "    def __init__(self,Encoder,ResBlock,Decoder):\n",
        "        super(generator, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder()\n",
        "        self.resblock = ResBlock()\n",
        "        self.decoder = Decoder()\n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.encoder(x)\n",
        "        for i in range(5):\n",
        "            x = self.resblock(x)\n",
        "        x = self.decoder(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCxx8eAXqVms",
        "colab_type": "text"
      },
      "source": [
        "### Define the discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdcipiFctMr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(discriminator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3,32,3,padding = 1)#128\n",
        "        self.norm1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32,64,3,padding = 1)#64\n",
        "        self.norm2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64,128,3,padding = 1)#16\n",
        "        self.norm3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128,256,3,padding = 1)#4\n",
        "        self.norm4 = nn.BatchNorm2d(256)\n",
        "        self.conv5 = nn.Conv2d(256,512,3,padding = 1)#1\n",
        "        self.norm5 = nn.BatchNorm2d(512)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.maxpool1 = nn.MaxPool2d(2,2)\n",
        "        self.maxpool2 = nn.MaxPool2d(4,4)\n",
        "        self.fc = nn.Linear(512,1)\n",
        "        self.softmax = nn.Sigmoid()\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        x = self.relu(self.norm1(self.conv1(x)))\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.relu(self.norm2(self.conv2(x)))\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.relu(self.norm3(self.conv3(x)))\n",
        "        x = self.maxpool2(x)\n",
        "        x = self.relu(self.norm4(self.conv4(x)))\n",
        "        x = self.maxpool2(x)\n",
        "        x = self.relu(self.norm5(self.conv5(x)))\n",
        "        x = self.maxpool2(x)\n",
        "        x = x.view(-1,512)\n",
        "        x = self.fc(x)\n",
        "        #x = self.softmax(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFNBBcP1qdsD",
        "colab_type": "text"
      },
      "source": [
        "### CUDA version for the nets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3umIdyT4xjed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G_x2y,G_y2x = generator(Encoder,ResBlock,Decoder).cuda(), generator(Encoder,ResBlock,Decoder).cuda()\n",
        "\n",
        "D_x, D_y = discriminator().cuda(), discriminator().cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVyrVRDFqpqB",
        "colab_type": "text"
      },
      "source": [
        "## Define the loss and optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-ZpFYGvq30R",
        "colab_type": "text"
      },
      "source": [
        "Gradient penalty for the wgan loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRQZw2AYgBy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_gradient_penalty(netD, real_data, fake_data, wgan_lambda, batch_size):\n",
        "    alpha = torch.rand(batch_size, 1)\n",
        "    alpha = alpha.expand(batch_size, int(real_data.nelement()/batch_size)).contiguous()\n",
        "    alpha = alpha.view(batch_size, 3, real_data.shape[2], real_data.shape[3])\n",
        "    alpha = alpha.cuda()\n",
        "\n",
        "    fake_data = fake_data.view(batch_size, 3, fake_data.shape[2], fake_data.shape[3])\n",
        "    interpolates = alpha * real_data.detach() + ((1 - alpha) * fake_data.detach())\n",
        "\n",
        "    interpolates = interpolates.cuda()\n",
        "    interpolates.requires_grad_(True)\n",
        "\n",
        "    disc_interpolates  = netD(interpolates)\n",
        "\n",
        "    gradients = grad(outputs=disc_interpolates, inputs=interpolates,\n",
        "                              grad_outputs=torch.ones(disc_interpolates.size()).cuda(),\n",
        "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * wgan_lambda\n",
        "\n",
        "    return gradient_penalty"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYMcQgEfrBdy",
        "colab_type": "text"
      },
      "source": [
        "Optimizers for each net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR_XGhpAzU4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer_G_x2y = torch.optim.Adam(G_x2y.parameters(), lr=0.0001, betas=(0,0.9))\n",
        "optimizer_G_y2x = torch.optim.Adam(G_y2x.parameters(), lr=0.0001, betas=(0,0.9))\n",
        "optimizer_D_x = torch.optim.Adam(D_x.parameters(), lr=0.0001, betas=(0,0.9))\n",
        "optimizer_D_y = torch.optim.Adam(D_y.parameters(), lr=0.0001, betas=(0,0.9))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhbwgMQ2rJFP",
        "colab_type": "text"
      },
      "source": [
        "Loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAnuJ-Oiz0GH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion_image = nn.L1Loss()\n",
        "criterion_type = nn.L1Loss()\n",
        "criterion_identity = nn.L1Loss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciZBPaVzrOCQ",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwhKAav70wyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the fake images pools\n",
        "x_fake_sample = Sample_from_Pool()\n",
        "y_fake_sample = Sample_from_Pool()\n",
        "#Record the loss for each epoch\n",
        "temp_G_list = []\n",
        "temp_D_X_list = []\n",
        "temp_D_Y_list = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "    temp_G = 0\n",
        "    temp_D_X = 0\n",
        "    temp_D_Y = 0\n",
        "\n",
        "    for batch_idx, (X_real, Y_real) in enumerate(trainloader):\n",
        "        # X=paintings, Y=photos\n",
        "        temp_G = 0\n",
        "        temp_D_X = 0\n",
        "        temp_D_Y = 0\n",
        "\n",
        "        G_x2y.train()\n",
        "        G_y2x.train()\n",
        "        D_x.train()\n",
        "        D_y.train()\n",
        "\n",
        "        if(Y_real.shape[0] < batch_size):\n",
        "            continue\n",
        "\n",
        "        G_x2y.zero_grad()\n",
        "        G_y2x.zero_grad()\n",
        "        #print(type(Y_real))\n",
        "        X_real, Y_real = Variable(X_real.float()).cuda(), Variable(Y_real.float()).cuda()\n",
        "        #print(type(Y_real))\n",
        "        X_fake = G_y2x(Y_real)      # real photos -> fake paintings\n",
        "        Y_fake = G_x2y(X_real)      # real paintings -> fake photos\n",
        "        X_cycle = G_y2x(Y_fake)     # fake photos -> real paintings\n",
        "        Y_cycle = G_x2y(X_fake)     # fake paintings -> real photos \n",
        "\n",
        "        D_X_real = D_x(X_real)      # predicted labels for real paintings\n",
        "        D_Y_real = D_y(Y_real)      # predicted labels for real photos\n",
        "        D_X_fake = D_x(X_fake)      # predicted labels for fake paintings\n",
        "        D_Y_fake = D_y(Y_fake)      # predicted labels for fake photos\n",
        "\n",
        "\n",
        "        real_label = Variable(torch.ones(D_Y_fake.size())).cuda()       #ones\n",
        "        fake_label = Variable(torch.zeros(D_Y_fake.size())).cuda()      #zeros\n",
        "\n",
        "        loss_cycle = criterion_image(X_real,X_cycle)+criterion_image(Y_real,Y_cycle)\n",
        "        real_label = Variable(torch.ones(D_Y_fake.size())).cuda()\n",
        "        loss_G_X2Y = criterion_type(D_Y_fake,real_label)\n",
        "        loss_G_Y2X = criterion_type(D_X_fake,real_label)\n",
        "        \n",
        "        loss_idt_A = 0\n",
        "        loss_idt_B = 0\n",
        "\n",
        "        # identity loss values taken from cyclegan defaults in the paper\n",
        "        lambda_identity_loss = 0.5\n",
        "        lambda_y = 10.0\n",
        "        lambda_x = 10.0\n",
        "\n",
        "        if lambda_identity_loss > 0:\n",
        "            I_x = G_x2y(Y_real)\n",
        "            I_y = G_y2x(X_real)\n",
        "\n",
        "            loss_idt_A = criterion_identity(I_x,Y_real) * lambda_y * lambda_identity_loss\n",
        "            loss_idt_B = criterion_identity(I_y,X_real) * lambda_x * lambda_identity_loss\n",
        "\n",
        "        # Total generator loss \n",
        "        G_loss = loss_G_X2Y + loss_G_Y2X + 10*loss_cycle + loss_idt_A + loss_idt_B\n",
        "        temp_G += G_loss.item()\n",
        "        G_loss.backward()\n",
        "\n",
        "        optimizer_G_x2y.step()\n",
        "        optimizer_G_y2x.step()\n",
        "        \n",
        "        # Get fake images from the images pool\n",
        "        X_fake = Variable(torch.Tensor(x_fake_sample([X_fake.cpu().data.numpy()])[0])).cuda()\n",
        "        Y_fake = Variable(torch.Tensor(y_fake_sample([Y_fake.cpu().data.numpy()])[0])).cuda()\n",
        "\n",
        "        D_x.zero_grad()\n",
        "        D_y.zero_grad()\n",
        "\n",
        "        D_X_real = D_x(X_real)          # identify true paintings\n",
        "        D_Y_real = D_y(Y_real)          # identify true photos\n",
        "        D_X_fake = D_x(X_fake_samp)     # identify fake paintings\n",
        "        D_Y_fake = D_y(Y_fake_samp)     # identfiy fake photos\n",
        "\n",
        "        real_label = Variable(torch.ones(D_Y_fake.size())).cuda()\n",
        "        fake_label = Variable(torch.zeros(D_Y_fake.size())).cuda()\n",
        "\n",
        "        # wgan loss from hw7\n",
        "        wgan_loss_d_x = 0\n",
        "        wgan_loss_d_y = 0\n",
        "        wgan_lambda = 10\n",
        "        if wgan_lambda > 0:\n",
        "            wgan_loss_d_x = calc_gradient_penalty(D_x, Y_real, Y_fake, wgan_lambda, batch_size)\n",
        "            wgan_loss_d_y = calc_gradient_penalty(D_y, X_real, X_fake, wgan_lambda, batch_size)\n",
        "\n",
        "        D_X_loss = criterion_type(D_X_fake,fake_label)+criterion_type(D_X_real,real_label) + wgan_loss_d_x\n",
        "        D_Y_loss = criterion_type(D_Y_fake,fake_label)+criterion_type(D_Y_real,real_label) + wgan_loss_d_y\n",
        "\n",
        "        D_X_loss.backward()\n",
        "        temp_D_X += D_X_loss.item()\n",
        "        optimizer_D_x.step()\n",
        "\n",
        "        D_Y_loss.backward()\n",
        "        temp_D_Y += D_Y_loss.item()\n",
        "        optimizer_D_y.step()\n",
        "\n",
        "        \n",
        "        \n",
        "    print(temp_G/batch_idx,temp_D_X/batch_idx,temp_D_Y/batch_idx)\n",
        "    temp_G_list.append(temp_G/batch_idx)\n",
        "    temp_D_X_list.append(temp_D_X/batch_idx)\n",
        "    temp_D_Y_list.append(temp_D_Y/batch_idx)\n",
        "    print('----EPOCH{} FINISHED-----'.format(epoch))\n",
        "\n",
        "    # output smaple images and save models for each 5 epochs\n",
        "    if epoch % 5 == 0:\n",
        "        im = plt.imread('/content/drive/My Drive/research/monet2photo/Test/monet/00010.jpg')\n",
        "        im = (im-np.min(im))/np.ptp(im)\n",
        "        input_im_holder = np.zeros((1,3,256,256))\n",
        "        im = np.moveaxis(im,(0,1,2),(1,2,0))\n",
        "        input_im_holder[0,:,:,:] = im\n",
        "        input_im = torch.from_numpy(input_im_holder).float().cuda()\n",
        "        out_im = G_x2y(input_im)\n",
        "        out_im = out_im.cpu().data.numpy()[0,:,:,:]\n",
        "        out_im = np.moveaxis(out_im,(0,1,2),(2,0,1))\n",
        "\n",
        "        out_im = (out_im-np.min(out_im))/np.ptp(out_im)\n",
        "\n",
        "        plt.imshow(out_im)\n",
        "        plt.show()\n",
        "        torch.save(G_x2y,\"/content/drive/My Drive/research/monet2photo/Test/models/G_x2y_{}.model\".format(epoch))\n",
        "        torch.save(G_y2x,\"/content/drive/My Drive/research/monet2photo/Test/models/G_y2x_{}.model\".format(epoch))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0vtPBrKs3W4",
        "colab_type": "text"
      },
      "source": [
        "## Saving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yF-R9Gi7tV0J",
        "colab_type": "text"
      },
      "source": [
        "Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nfNRGVUISG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G_x2y = torch.load(\"/content/drive/My Drive/research/monet2photo/Test/models/G_x2y_105.model\")\n",
        "G_y2x = torch.load(\"/content/drive/My Drive/research/monet2photo/Test/models/G_y2x_75.model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyVXGulEtbaj",
        "colab_type": "text"
      },
      "source": [
        "Save painting -> photo results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9rBCSmqEcMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "monet_image = os.listdir('/content/drive/My Drive/research/monet2photo/Test/monet/')\n",
        "path = '/content/drive/My Drive/research/monet2photo/Test/monet/'\n",
        "for name in monet_image:\n",
        "    im = plt.imread(path+name)\n",
        "    im = (im-np.min(im))/np.ptp(im)\n",
        "    input_im_holder = np.zeros((1,3,256,256))\n",
        "    im = np.moveaxis(im,(0,1,2),(1,2,0))\n",
        "    input_im_holder[0,:,:,:] = im\n",
        "    input_im = torch.from_numpy(input_im_holder).float().cuda()\n",
        "    out_im = G_x2y(input_im)\n",
        "    out_im = out_im.cpu().data.numpy()[0,:,:,:]\n",
        "    out_im = np.moveaxis(out_im,(0,1,2),(2,0,1))\n",
        "\n",
        "    out_im = (out_im-np.min(out_im))/np.ptp(out_im)\n",
        "\n",
        "    plt.imsave('/content/drive/My Drive/research/monet2photo/Test/'+'monet_to_photo/'+name,out_im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3nDpG1qtaJJ",
        "colab_type": "text"
      },
      "source": [
        "Save photo->image results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_DSbq9JAfW8",
        "colab_type": "code",
        "outputId": "70def071-6367-4450-f71a-26cd665f159b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "\n",
        "\n",
        "monet_image = os.listdir('/content/drive/My Drive/research/monet2photo/Test/photo/')\n",
        "path = '/content/drive/My Drive/research/monet2photo/Test/photo/'\n",
        "for name in monet_image:\n",
        "    im = plt.imread(path+name)\n",
        "    im = (im-np.min(im))/np.ptp(im)\n",
        "    input_im_holder = np.zeros((1,3,256,256))\n",
        "    im = np.moveaxis(im,(0,1,2),(1,2,0))\n",
        "    input_im_holder[0,:,:,:] = im\n",
        "    input_im = torch.from_numpy(input_im_holder).float().cuda()\n",
        "    out_im = G_y2x(input_im)\n",
        "    out_im = out_im.cpu().data.numpy()[0,:,:,:]\n",
        "    out_im = np.moveaxis(out_im,(0,1,2),(2,0,1))\n",
        "\n",
        "    out_im = (out_im-np.min(out_im))/np.ptp(out_im)\n",
        "\n",
        "    plt.imsave('/content/drive/My Drive/research/monet2photo/Test/'+'photo_to_monet/'+'75'+name,out_im)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmH93z9lBWRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}